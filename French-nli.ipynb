{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "934ed815",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext nb_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "306cd498",
   "metadata": {},
   "outputs": [],
   "source": [
    "%env HF_DATASETS_CACHE=\"/data/users/sgarg6/hf_cache\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3aa6a101",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"/data/users/sgarg6/hf_cache\"\r\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 3;\n",
       "                var nbb_unformatted_code = \"!echo $HF_DATASETS_CACHE\";\n",
       "                var nbb_formatted_code = \"!echo $HF_DATASETS_CACHE\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "!echo $HF_DATASETS_CACHE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1dbaf82c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 4;\n",
       "                var nbb_unformatted_code = \"import torch\\n\\ndevice = \\\"cuda\\\" if torch.cuda.is_available() else \\\"cpu\\\"\";\n",
       "                var nbb_formatted_code = \"import torch\\n\\ndevice = \\\"cuda\\\" if torch.cuda.is_available() else \\\"cpu\\\"\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fae0c15b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 5;\n",
       "                var nbb_unformatted_code = \"from datasets import load_dataset\\n\\n# dataset = load_dataset('snli')\";\n",
       "                var nbb_formatted_code = \"from datasets import load_dataset\\n\\n# dataset = load_dataset('snli')\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# dataset = load_dataset('snli')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ae09ab29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 6;\n",
       "                var nbb_unformatted_code = \"# from transformers import T5Tokenizer, T5ForConditionalGeneration\\n\\n# tokenizer = T5Tokenizer.from_pretrained(\\\"t5-small\\\")\\n# model = T5ForConditionalGeneration.from_pretrained(\\\"t5-small\\\").to(device)\\n\\n# input_ids = tokenizer(\\n#     \\\"translate English to French: The house is wonderful.\\\", return_tensors=\\\"pt\\\"\\n# ).input_ids.to(device)\\n# outputs = model.generate(input_ids)\\n# print(tokenizer.decode(outputs[0], skip_special_tokens=True))\";\n",
       "                var nbb_formatted_code = \"# from transformers import T5Tokenizer, T5ForConditionalGeneration\\n\\n# tokenizer = T5Tokenizer.from_pretrained(\\\"t5-small\\\")\\n# model = T5ForConditionalGeneration.from_pretrained(\\\"t5-small\\\").to(device)\\n\\n# input_ids = tokenizer(\\n#     \\\"translate English to French: The house is wonderful.\\\", return_tensors=\\\"pt\\\"\\n# ).input_ids.to(device)\\n# outputs = model.generate(input_ids)\\n# print(tokenizer.decode(outputs[0], skip_special_tokens=True))\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "\n",
    "# tokenizer = T5Tokenizer.from_pretrained(\"t5-small\")\n",
    "# model = T5ForConditionalGeneration.from_pretrained(\"t5-small\").to(device)\n",
    "\n",
    "# input_ids = tokenizer(\n",
    "#     \"translate English to French: The house is wonderful.\", return_tensors=\"pt\"\n",
    "# ).input_ids.to(device)\n",
    "# outputs = model.generate(input_ids)\n",
    "# print(tokenizer.decode(outputs[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0b9ff6e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 7;\n",
       "                var nbb_unformatted_code = \"def translate(sentence):\\n    sentence = [\\\"translate English to French: \\\" + sent for sent in sentence]\\n    input_ids = tokenizer(\\n        sentence, return_tensors=\\\"pt\\\", truncation=True, padding=True\\n    ).input_ids.to(device)\\n    outputs = model.generate(input_ids)\\n    return tokenizer.batch_decode(outputs, skip_special_tokens=True)\";\n",
       "                var nbb_formatted_code = \"def translate(sentence):\\n    sentence = [\\\"translate English to French: \\\" + sent for sent in sentence]\\n    input_ids = tokenizer(\\n        sentence, return_tensors=\\\"pt\\\", truncation=True, padding=True\\n    ).input_ids.to(device)\\n    outputs = model.generate(input_ids)\\n    return tokenizer.batch_decode(outputs, skip_special_tokens=True)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def translate(sentence):\n",
    "    sentence = [\"translate English to French: \" + sent for sent in sentence]\n",
    "    input_ids = tokenizer(\n",
    "        sentence, return_tensors=\"pt\", truncation=True, padding=True\n",
    "    ).input_ids.to(device)\n",
    "    outputs = model.generate(input_ids)\n",
    "    return tokenizer.batch_decode(outputs, skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1c767b82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 8;\n",
       "                var nbb_unformatted_code = \"def add_translations(example):\\n    example[\\\"translated_premise\\\"] = translate(example[\\\"premise\\\"])\\n    example[\\\"translated_hypothesis\\\"] = translate(example[\\\"hypothesis\\\"])\\n    return example\\n\\n\\n# updated_dataset = dataset.map(add_translations, batched=True, batch_size=128)\";\n",
       "                var nbb_formatted_code = \"def add_translations(example):\\n    example[\\\"translated_premise\\\"] = translate(example[\\\"premise\\\"])\\n    example[\\\"translated_hypothesis\\\"] = translate(example[\\\"hypothesis\\\"])\\n    return example\\n\\n\\n# updated_dataset = dataset.map(add_translations, batched=True, batch_size=128)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def add_translations(example):\n",
    "    example[\"translated_premise\"] = translate(example[\"premise\"])\n",
    "    example[\"translated_hypothesis\"] = translate(example[\"hypothesis\"])\n",
    "    return example\n",
    "\n",
    "\n",
    "# updated_dataset = dataset.map(add_translations, batched=True, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "93dfe596",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 9;\n",
       "                var nbb_unformatted_code = \"import os\\n\\n# updated_dataset.save_to_disk(\\n#    os.path.join(os.environ[\\\"HF_DATASETS_CACHE\\\"], \\\"french-snli.hf\\\")\\n# )\";\n",
       "                var nbb_formatted_code = \"import os\\n\\n# updated_dataset.save_to_disk(\\n#    os.path.join(os.environ[\\\"HF_DATASETS_CACHE\\\"], \\\"french-snli.hf\\\")\\n# )\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# updated_dataset.save_to_disk(\n",
    "#    os.path.join(os.environ[\"HF_DATASETS_CACHE\"], \"french-snli.hf\")\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2e8d58ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 10;\n",
       "                var nbb_unformatted_code = \"import datasets\\ndataset = datasets.load_from_disk(os.path.join(os.environ[\\\"HF_DATASETS_CACHE\\\"], \\\"french-snli.hf\\\"))\";\n",
       "                var nbb_formatted_code = \"import datasets\\n\\ndataset = datasets.load_from_disk(\\n    os.path.join(os.environ[\\\"HF_DATASETS_CACHE\\\"], \\\"french-snli.hf\\\")\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import datasets\n",
    "dataset = datasets.load_from_disk(os.path.join(os.environ[\"HF_DATASETS_CACHE\"], \"french-snli.hf\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "806e3406",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 11;\n",
       "                var nbb_unformatted_code = \"# updated_dataset.push_to_hub(\\\"sugam11/french-snli\\\")\";\n",
       "                var nbb_formatted_code = \"# updated_dataset.push_to_hub(\\\"sugam11/french-snli\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# updated_dataset.push_to_hub(\"sugam11/french-snli\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6e006af3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    test: Dataset({\n",
       "        features: ['premise', 'hypothesis', 'label', 'translated_premise', 'translated_hypothesis'],\n",
       "        num_rows: 10000\n",
       "    })\n",
       "    train: Dataset({\n",
       "        features: ['premise', 'hypothesis', 'label', 'translated_premise', 'translated_hypothesis'],\n",
       "        num_rows: 550152\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['premise', 'hypothesis', 'label', 'translated_premise', 'translated_hypothesis'],\n",
       "        num_rows: 10000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 12;\n",
       "                var nbb_unformatted_code = \"dataset\";\n",
       "                var nbb_formatted_code = \"dataset\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ca00dd15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 13;\n",
       "                var nbb_unformatted_code = \"dataset[\\\"train\\\"][1][\\\"label\\\"]\";\n",
       "                var nbb_formatted_code = \"dataset[\\\"train\\\"][1][\\\"label\\\"]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset[\"train\"][1][\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "51e582a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 14;\n",
       "                var nbb_unformatted_code = \"id2label = {1: \\\"NEUTRAL\\\", 0: \\\"ENTAILMENT\\\", 2: \\\"CONTRADICTION\\\"}\\nlabel2id = {\\\"ENTAILMENT\\\": 0, \\\"NEUTRAL\\\": 1, \\\"CONTRADICTION\\\": 2}\";\n",
       "                var nbb_formatted_code = \"id2label = {1: \\\"NEUTRAL\\\", 0: \\\"ENTAILMENT\\\", 2: \\\"CONTRADICTION\\\"}\\nlabel2id = {\\\"ENTAILMENT\\\": 0, \\\"NEUTRAL\\\": 1, \\\"CONTRADICTION\\\": 2}\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "id2label = {1: \"NEUTRAL\", 0: \"ENTAILMENT\", 2: \"CONTRADICTION\"}\n",
    "label2id = {\"ENTAILMENT\": 0, \"NEUTRAL\": 1, \"CONTRADICTION\": 2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "74e69503",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file config.json from cache at /soe/sgarg6/.cache/huggingface/hub/models--cmarkea--distilcamembert-base/snapshots/5ec21d6a99a79dfa45f5557f3e28f31e22673578/config.json\n",
      "Model config CamembertConfig {\n",
      "  \"_name_or_path\": \"cmarkea/distilcamembert-base\",\n",
      "  \"architectures\": [\n",
      "    \"CamembertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"camembert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.24.0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32005\n",
      "}\n",
      "\n",
      "loading file sentencepiece.bpe.model from cache at /soe/sgarg6/.cache/huggingface/hub/models--cmarkea--distilcamembert-base/snapshots/5ec21d6a99a79dfa45f5557f3e28f31e22673578/sentencepiece.bpe.model\n",
      "loading file tokenizer.json from cache at None\n",
      "loading file added_tokens.json from cache at None\n",
      "loading file special_tokens_map.json from cache at None\n",
      "loading file tokenizer_config.json from cache at /soe/sgarg6/.cache/huggingface/hub/models--cmarkea--distilcamembert-base/snapshots/5ec21d6a99a79dfa45f5557f3e28f31e22673578/tokenizer_config.json\n",
      "loading configuration file config.json from cache at /soe/sgarg6/.cache/huggingface/hub/models--cmarkea--distilcamembert-base/snapshots/5ec21d6a99a79dfa45f5557f3e28f31e22673578/config.json\n",
      "Model config CamembertConfig {\n",
      "  \"_name_or_path\": \"cmarkea/distilcamembert-base\",\n",
      "  \"architectures\": [\n",
      "    \"CamembertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"camembert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.24.0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32005\n",
      "}\n",
      "\n",
      "loading configuration file config.json from cache at /soe/sgarg6/.cache/huggingface/hub/models--cmarkea--distilcamembert-base/snapshots/5ec21d6a99a79dfa45f5557f3e28f31e22673578/config.json\n",
      "Model config CamembertConfig {\n",
      "  \"_name_or_path\": \"cmarkea/distilcamembert-base\",\n",
      "  \"architectures\": [\n",
      "    \"CamembertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"camembert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.24.0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32005\n",
      "}\n",
      "\n",
      "loading configuration file config.json from cache at /soe/sgarg6/.cache/huggingface/hub/models--cmarkea--distilcamembert-base/snapshots/5ec21d6a99a79dfa45f5557f3e28f31e22673578/config.json\n",
      "Model config CamembertConfig {\n",
      "  \"_name_or_path\": \"cmarkea/distilcamembert-base\",\n",
      "  \"architectures\": [\n",
      "    \"CamembertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"ENTAILMENT\",\n",
      "    \"1\": \"NEUTRAL\",\n",
      "    \"2\": \"CONTRADICTION\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"CONTRADICTION\": 2,\n",
      "    \"ENTAILMENT\": 0,\n",
      "    \"NEUTRAL\": 1\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"camembert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.24.0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32005\n",
      "}\n",
      "\n",
      "loading weights file pytorch_model.bin from cache at /soe/sgarg6/.cache/huggingface/hub/models--cmarkea--distilcamembert-base/snapshots/5ec21d6a99a79dfa45f5557f3e28f31e22673578/pytorch_model.bin\n",
      "Some weights of the model checkpoint at cmarkea/distilcamembert-base were not used when initializing CamembertForSequenceClassification: ['lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.decoder.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing CamembertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing CamembertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of CamembertForSequenceClassification were not initialized from the model checkpoint at cmarkea/distilcamembert-base and are newly initialized: ['classifier.out_proj.bias', 'classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 99;\n",
       "                var nbb_unformatted_code = \"from transformers import AutoTokenizer, AutoModelForSequenceClassification\\n\\ntokenizer = AutoTokenizer.from_pretrained(\\\"cmarkea/distilcamembert-base\\\")\\nmodel = AutoModelForSequenceClassification.from_pretrained(\\n    \\\"cmarkea/distilcamembert-base\\\", num_labels=3, id2label=id2label, label2id=label2id\\n)\";\n",
       "                var nbb_formatted_code = \"from transformers import AutoTokenizer, AutoModelForSequenceClassification\\n\\ntokenizer = AutoTokenizer.from_pretrained(\\\"cmarkea/distilcamembert-base\\\")\\nmodel = AutoModelForSequenceClassification.from_pretrained(\\n    \\\"cmarkea/distilcamembert-base\\\", num_labels=3, id2label=id2label, label2id=label2id\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"cmarkea/distilcamembert-base\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"cmarkea/distilcamembert-base\", num_labels=3, id2label=id2label, label2id=label2id\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "fce61c72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CamembertForSequenceClassification(\n",
      "  (roberta): CamembertModel(\n",
      "    (embeddings): CamembertEmbeddings(\n",
      "      (word_embeddings): Embedding(32005, 768, padding_idx=1)\n",
      "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
      "      (token_type_embeddings): Embedding(1, 768)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (encoder): CamembertEncoder(\n",
      "      (layer): ModuleList(\n",
      "        (0): CamembertLayer(\n",
      "          (attention): CamembertAttention(\n",
      "            (self): CamembertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): CamembertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): CamembertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): CamembertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (1): CamembertLayer(\n",
      "          (attention): CamembertAttention(\n",
      "            (self): CamembertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): CamembertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): CamembertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): CamembertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (2): CamembertLayer(\n",
      "          (attention): CamembertAttention(\n",
      "            (self): CamembertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): CamembertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): CamembertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): CamembertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (3): CamembertLayer(\n",
      "          (attention): CamembertAttention(\n",
      "            (self): CamembertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): CamembertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): CamembertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): CamembertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (4): CamembertLayer(\n",
      "          (attention): CamembertAttention(\n",
      "            (self): CamembertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): CamembertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): CamembertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): CamembertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (5): CamembertLayer(\n",
      "          (attention): CamembertAttention(\n",
      "            (self): CamembertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): CamembertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): CamembertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): CamembertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (classifier): CamembertClassificationHead(\n",
      "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "    (out_proj): Linear(in_features=768, out_features=3, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 100;\n",
       "                var nbb_unformatted_code = \"print(model)\";\n",
       "                var nbb_formatted_code = \"print(model)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c1eb6067",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 17;\n",
       "                var nbb_unformatted_code = \"model = model.to(device)\";\n",
       "                var nbb_formatted_code = \"model = model.to(device)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e01240d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<s>'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 18;\n",
       "                var nbb_unformatted_code = \"tokenizer.cls_token\";\n",
       "                var nbb_formatted_code = \"tokenizer.cls_token\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer.cls_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0068918f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /soe/sgarg6/course_work/244_nlp/french-nli/\"/data/users/sgarg6/hf_cache\"/french-snli.hf/test/cache-ba63908f97e3c3d6.arrow\n",
      "Loading cached processed dataset at /soe/sgarg6/course_work/244_nlp/french-nli/\"/data/users/sgarg6/hf_cache\"/french-snli.hf/train/cache-6ccf969afd688925.arrow\n",
      "Loading cached processed dataset at /soe/sgarg6/course_work/244_nlp/french-nli/\"/data/users/sgarg6/hf_cache\"/french-snli.hf/validation/cache-f19de9a01de521d4.arrow\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 19;\n",
       "                var nbb_unformatted_code = \"# Modify dataset for NLI task\\n\\n\\ndef combine_data(sample):\\n    text = (\\n        tokenizer.cls_token\\n        + \\\" \\\"\\n        + sample[\\\"translated_premise\\\"]\\n        + \\\" \\\"\\n        + tokenizer.sep_token\\n        + \\\" \\\"\\n        + sample[\\\"translated_hypothesis\\\"]\\n    )\\n    sample[\\\"text\\\"] = text\\n    return sample\\n\\n\\ndataset = dataset.map(combine_data)\";\n",
       "                var nbb_formatted_code = \"# Modify dataset for NLI task\\n\\n\\ndef combine_data(sample):\\n    text = (\\n        tokenizer.cls_token\\n        + \\\" \\\"\\n        + sample[\\\"translated_premise\\\"]\\n        + \\\" \\\"\\n        + tokenizer.sep_token\\n        + \\\" \\\"\\n        + sample[\\\"translated_hypothesis\\\"]\\n    )\\n    sample[\\\"text\\\"] = text\\n    return sample\\n\\n\\ndataset = dataset.map(combine_data)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Modify dataset for NLI task\n",
    "\n",
    "\n",
    "def combine_data(sample):\n",
    "    text = (\n",
    "        tokenizer.cls_token\n",
    "        + \" \"\n",
    "        + sample[\"translated_premise\"]\n",
    "        + \" \"\n",
    "        + tokenizer.sep_token\n",
    "        + \" \"\n",
    "        + sample[\"translated_hypothesis\"]\n",
    "    )\n",
    "    sample[\"text\"] = text\n",
    "    return sample\n",
    "\n",
    "\n",
    "dataset = dataset.map(combine_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d57661da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /soe/sgarg6/course_work/244_nlp/french-nli/\"/data/users/sgarg6/hf_cache\"/french-snli.hf/test/cache-4e837b395511e86c.arrow\n",
      "Loading cached processed dataset at /soe/sgarg6/course_work/244_nlp/french-nli/\"/data/users/sgarg6/hf_cache\"/french-snli.hf/train/cache-19d6a619341e65a2.arrow\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f179f6e1257b4f1bac34966d2dcb8856",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 20;\n",
       "                var nbb_unformatted_code = \"# Tokenize the dataset\\n\\ndataset = dataset.map(\\n    lambda x: tokenizer(x[\\\"text\\\"], truncation=True, padding=True),\\n    batched=True,\\n    batch_size=128,\\n)\";\n",
       "                var nbb_formatted_code = \"# Tokenize the dataset\\n\\ndataset = dataset.map(\\n    lambda x: tokenizer(x[\\\"text\\\"], truncation=True, padding=True),\\n    batched=True,\\n    batch_size=128,\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Tokenize the dataset\n",
    "\n",
    "dataset = dataset.map(\n",
    "    lambda x: tokenizer(x[\"text\"], truncation=True, padding=True),\n",
    "    batched=True,\n",
    "    batch_size=128,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "52f51dc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /soe/sgarg6/course_work/244_nlp/french-nli/\"/data/users/sgarg6/hf_cache\"/french-snli.hf/test/cache-88b40878938667c2.arrow\n",
      "Loading cached processed dataset at /soe/sgarg6/course_work/244_nlp/french-nli/\"/data/users/sgarg6/hf_cache\"/french-snli.hf/train/cache-08bf3652d03f0adc.arrow\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e92736d4166f413790f070fe9ca08b1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 21;\n",
       "                var nbb_unformatted_code = \"dataset = dataset.filter(lambda sample: sample[\\\"label\\\"] >= 0)\";\n",
       "                var nbb_formatted_code = \"dataset = dataset.filter(lambda sample: sample[\\\"label\\\"] >= 0)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = dataset.filter(lambda sample: sample[\"label\"] >= 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5b8c38c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    test: Dataset({\n",
       "        features: ['premise', 'hypothesis', 'label', 'translated_premise', 'translated_hypothesis', 'text', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 9824\n",
       "    })\n",
       "    train: Dataset({\n",
       "        features: ['premise', 'hypothesis', 'label', 'translated_premise', 'translated_hypothesis', 'text', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 549367\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['premise', 'hypothesis', 'label', 'translated_premise', 'translated_hypothesis', 'text', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 9842\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 22;\n",
       "                var nbb_unformatted_code = \"dataset\";\n",
       "                var nbb_formatted_code = \"dataset\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8aeb5d1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 23;\n",
       "                var nbb_unformatted_code = \"# convert train set to tensors with only model inputs\\ndataset.set_format(type=\\\"pt\\\", columns=[\\\"input_ids\\\", \\\"attention_mask\\\", \\\"label\\\"])\";\n",
       "                var nbb_formatted_code = \"# convert train set to tensors with only model inputs\\ndataset.set_format(type=\\\"pt\\\", columns=[\\\"input_ids\\\", \\\"attention_mask\\\", \\\"label\\\"])\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# convert train set to tensors with only model inputs\n",
    "dataset.set_format(type=\"pt\", columns=[\"input_ids\", \"attention_mask\", \"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2a57a3b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 24;\n",
       "                var nbb_unformatted_code = \"dataset[\\\"train\\\"][\\\"label\\\"].unique()\";\n",
       "                var nbb_formatted_code = \"dataset[\\\"train\\\"][\\\"label\\\"].unique()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset[\"train\"][\"label\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b90c5dde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:hpnlhdqf) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a437e60262304e7383c5e373dfd9d946",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.004 MB of 0.004 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train/epoch</td><td>▁▃▅▆█▁▃▅▆█</td></tr><tr><td>train/global_step</td><td>▁▃▅▆█▁▃▅▆█</td></tr><tr><td>train/learning_rate</td><td>█▆▅▃▁█▆▅▃▁</td></tr><tr><td>train/loss</td><td>█▅▄▄▄▃▂▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train/epoch</td><td>0.12</td></tr><tr><td>train/global_step</td><td>250</td></tr><tr><td>train/learning_rate</td><td>4e-05</td></tr><tr><td>train/loss</td><td>0.5726</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">sunny-aardvark-4</strong> at: <a href='https://wandb.ai/sugam110795/nlp244/runs/hpnlhdqf' target=\"_blank\">https://wandb.ai/sugam110795/nlp244/runs/hpnlhdqf</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230219_112435-hpnlhdqf/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:hpnlhdqf). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7c5401ff898440ba65be4e751ae9cb1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016668950549016397, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.10"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/soe/sgarg6/course_work/244_nlp/french-nli/wandb/run-20230219_113853-5ww107vn</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/sugam110795/nlp244/runs/5ww107vn' target=\"_blank\">solar-wind-5</a></strong> to <a href='https://wandb.ai/sugam110795/nlp244' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/sugam110795/nlp244' target=\"_blank\">https://wandb.ai/sugam110795/nlp244</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/sugam110795/nlp244/runs/5ww107vn' target=\"_blank\">https://wandb.ai/sugam110795/nlp244/runs/5ww107vn</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/sugam110795/nlp244/runs/5ww107vn?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7f9c20e28430>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 38;\n",
       "                var nbb_unformatted_code = \"import wandb\\n\\nwandb.init(entity=\\\"sugam110795\\\", project=\\\"nlp244\\\", group=\\\"quest4\\\")\";\n",
       "                var nbb_formatted_code = \"import wandb\\n\\nwandb.init(entity=\\\"sugam110795\\\", project=\\\"nlp244\\\", group=\\\"quest4\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import wandb\n",
    "\n",
    "wandb.init(entity=\"sugam110795\", project=\"nlp244\", group=\"quest4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "72713be8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 101;\n",
       "                var nbb_unformatted_code = \"from evaluate import Metric, EvaluationModuleInfo\\nfrom typing import Dict, Any\\nfrom sklearn.metrics import f1_score\\n\\n\\nclass MyMacroF1Metric(Metric):\\n    \\\"\\\"\\\"\\n    You can define custom metrics! In this case I do this to compute Macro-F1, which averages per-class F1 scores\\n    \\\"\\\"\\\"\\n\\n    f1_metric_info: EvaluationModuleInfo = evaluate.load(\\\"f1\\\")._info()\\n\\n    def _info(self) -> EvaluationModuleInfo:\\n        # we'll just say the info is the same in this case\\n        return MyMacroF1Metric.f1_metric_info\\n\\n    def _compute(\\n        self,\\n        predictions=None,\\n        references=None,\\n        labels=None,\\n        pos_label=1,\\n        sample_weight=None,\\n    ) -> Dict[str, Any]:\\n        # we can just call the sklearn implementation! Metrics in huggingface generally correspond with sklearn metrics\\n        # when applicable\\n        score = f1_score(\\n            references,\\n            predictions,\\n            labels=labels,\\n            pos_label=pos_label,\\n            average=\\\"macro\\\",\\n            sample_weight=sample_weight,\\n        )\\n        return {\\\"f1\\\": float(score) if score.size == 1 else score}\";\n",
       "                var nbb_formatted_code = \"from evaluate import Metric, EvaluationModuleInfo\\nfrom typing import Dict, Any\\nfrom sklearn.metrics import f1_score\\n\\n\\nclass MyMacroF1Metric(Metric):\\n    \\\"\\\"\\\"\\n    You can define custom metrics! In this case I do this to compute Macro-F1, which averages per-class F1 scores\\n    \\\"\\\"\\\"\\n\\n    f1_metric_info: EvaluationModuleInfo = evaluate.load(\\\"f1\\\")._info()\\n\\n    def _info(self) -> EvaluationModuleInfo:\\n        # we'll just say the info is the same in this case\\n        return MyMacroF1Metric.f1_metric_info\\n\\n    def _compute(\\n        self,\\n        predictions=None,\\n        references=None,\\n        labels=None,\\n        pos_label=1,\\n        sample_weight=None,\\n    ) -> Dict[str, Any]:\\n        # we can just call the sklearn implementation! Metrics in huggingface generally correspond with sklearn metrics\\n        # when applicable\\n        score = f1_score(\\n            references,\\n            predictions,\\n            labels=labels,\\n            pos_label=pos_label,\\n            average=\\\"macro\\\",\\n            sample_weight=sample_weight,\\n        )\\n        return {\\\"f1\\\": float(score) if score.size == 1 else score}\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from evaluate import Metric, EvaluationModuleInfo\n",
    "from typing import Dict, Any\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "\n",
    "class MyMacroF1Metric(Metric):\n",
    "    \"\"\"\n",
    "    You can define custom metrics! In this case I do this to compute Macro-F1, which averages per-class F1 scores\n",
    "    \"\"\"\n",
    "\n",
    "    f1_metric_info: EvaluationModuleInfo = evaluate.load(\"f1\")._info()\n",
    "\n",
    "    def _info(self) -> EvaluationModuleInfo:\n",
    "        # we'll just say the info is the same in this case\n",
    "        return MyMacroF1Metric.f1_metric_info\n",
    "\n",
    "    def _compute(\n",
    "        self,\n",
    "        predictions=None,\n",
    "        references=None,\n",
    "        labels=None,\n",
    "        pos_label=1,\n",
    "        sample_weight=None,\n",
    "    ) -> Dict[str, Any]:\n",
    "        # we can just call the sklearn implementation! Metrics in huggingface generally correspond with sklearn metrics\n",
    "        # when applicable\n",
    "        score = f1_score(\n",
    "            references,\n",
    "            predictions,\n",
    "            labels=labels,\n",
    "            pos_label=pos_label,\n",
    "            average=\"macro\",\n",
    "            sample_weight=sample_weight,\n",
    "        )\n",
    "        return {\"f1\": float(score) if score.size == 1 else score}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "1509de0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 107;\n",
       "                var nbb_unformatted_code = \"import evaluate\\n\\n# my_evaluation = evaluate.combine([\\\"accuracy\\\", \\\"f1\\\"])\\n\\nmy_evaluation = evaluate.combine(\\n    [\\n        evaluate.load(\\\"accuracy\\\", average=\\\"weighted\\\"),\\n        MyMacroF1Metric(),\\n    ]\\n)\";\n",
       "                var nbb_formatted_code = \"import evaluate\\n\\n# my_evaluation = evaluate.combine([\\\"accuracy\\\", \\\"f1\\\"])\\n\\nmy_evaluation = evaluate.combine(\\n    [\\n        evaluate.load(\\\"accuracy\\\", average=\\\"weighted\\\"),\\n        MyMacroF1Metric(),\\n    ]\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import evaluate\n",
    "\n",
    "# my_evaluation = evaluate.combine([\"accuracy\", \"f1\"])\n",
    "\n",
    "my_evaluation = evaluate.combine(\n",
    "    [\n",
    "        evaluate.load(\"accuracy\", average=\"weighted\"),\n",
    "        MyMacroF1Metric(),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "9a22fa9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 108;\n",
       "                var nbb_unformatted_code = \"from transformers import TrainingArguments\\nfrom sklearn.metrics import accuracy_score\\n\\ntraining_args: TrainingArguments = TrainingArguments(\\n    output_dir=\\\"/data/users/sgarg6/hf_models/quest-4\\\",\\n    do_train=True,\\n    do_eval=True,\\n    do_predict=True,\\n    evaluation_strategy=\\\"steps\\\",\\n    eval_steps=256,\\n    per_device_train_batch_size=256,\\n    per_device_eval_batch_size=256,\\n    save_steps=256,\\n    save_strategy=\\\"steps\\\",\\n    save_total_limit=5,\\n    report_to=[\\\"wandb\\\"],\\n    logging_steps=50,\\n    num_train_epochs=1,\\n    metric_for_best_model=\\\"accuracy\\\",\\n    load_best_model_at_end=True,\\n    dataloader_num_workers=0,  # set to 0 when debugging and >1 when running!\\n)\";\n",
       "                var nbb_formatted_code = \"from transformers import TrainingArguments\\nfrom sklearn.metrics import accuracy_score\\n\\ntraining_args: TrainingArguments = TrainingArguments(\\n    output_dir=\\\"/data/users/sgarg6/hf_models/quest-4\\\",\\n    do_train=True,\\n    do_eval=True,\\n    do_predict=True,\\n    evaluation_strategy=\\\"steps\\\",\\n    eval_steps=256,\\n    per_device_train_batch_size=256,\\n    per_device_eval_batch_size=256,\\n    save_steps=256,\\n    save_strategy=\\\"steps\\\",\\n    save_total_limit=5,\\n    report_to=[\\\"wandb\\\"],\\n    logging_steps=50,\\n    num_train_epochs=1,\\n    metric_for_best_model=\\\"accuracy\\\",\\n    load_best_model_at_end=True,\\n    dataloader_num_workers=0,  # set to 0 when debugging and >1 when running!\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import TrainingArguments\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "training_args: TrainingArguments = TrainingArguments(\n",
    "    output_dir=\"/data/users/sgarg6/hf_models/quest-4\",\n",
    "    do_train=True,\n",
    "    do_eval=True,\n",
    "    do_predict=True,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=256,\n",
    "    per_device_train_batch_size=256,\n",
    "    per_device_eval_batch_size=256,\n",
    "    save_steps=256,\n",
    "    save_strategy=\"steps\",\n",
    "    save_total_limit=5,\n",
    "    report_to=[\"wandb\"],\n",
    "    logging_steps=50,\n",
    "    num_train_epochs=1,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    load_best_model_at_end=True,\n",
    "    dataloader_num_workers=0,  # set to 0 when debugging and >1 when running!\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "2fdca7bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 109;\n",
       "                var nbb_unformatted_code = \"from transformers import EvalPrediction\\nfrom typing import Dict, Tuple\\n\\n\\ndef my_compute_metrics(eval_pred: EvalPrediction) -> Dict[str, float]:\\n    logits, labels = eval_pred.predictions, eval_pred.label_ids\\n    predictions: Tensor = logits.argmax(axis=1)\\n    return my_evaluation.compute(predictions=predictions, references=labels)\";\n",
       "                var nbb_formatted_code = \"from transformers import EvalPrediction\\nfrom typing import Dict, Tuple\\n\\n\\ndef my_compute_metrics(eval_pred: EvalPrediction) -> Dict[str, float]:\\n    logits, labels = eval_pred.predictions, eval_pred.label_ids\\n    predictions: Tensor = logits.argmax(axis=1)\\n    return my_evaluation.compute(predictions=predictions, references=labels)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import EvalPrediction\n",
    "from typing import Dict, Tuple\n",
    "\n",
    "\n",
    "def my_compute_metrics(eval_pred: EvalPrediction) -> Dict[str, float]:\n",
    "    logits, labels = eval_pred.predictions, eval_pred.label_ids\n",
    "    predictions: Tensor = logits.argmax(axis=1)\n",
    "    return my_evaluation.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "3a011db9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 110;\n",
       "                var nbb_unformatted_code = \"from transformers import Trainer\\n\\ntrainer: Trainer = Trainer(\\n    model=model,\\n    args=training_args,\\n    data_collator=None,  # let HF set this to an instance of transformers.DataCollatorWithPadding\\n    train_dataset=dataset[\\\"train\\\"],\\n    eval_dataset=dataset[\\\"validation\\\"],\\n    tokenizer=tokenizer,\\n    compute_metrics=my_compute_metrics,\\n)\";\n",
       "                var nbb_formatted_code = \"from transformers import Trainer\\n\\ntrainer: Trainer = Trainer(\\n    model=model,\\n    args=training_args,\\n    data_collator=None,  # let HF set this to an instance of transformers.DataCollatorWithPadding\\n    train_dataset=dataset[\\\"train\\\"],\\n    eval_dataset=dataset[\\\"validation\\\"],\\n    tokenizer=tokenizer,\\n    compute_metrics=my_compute_metrics,\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import Trainer\n",
    "\n",
    "trainer: Trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=None,  # let HF set this to an instance of transformers.DataCollatorWithPadding\n",
    "    train_dataset=dataset[\"train\"],\n",
    "    eval_dataset=dataset[\"validation\"],\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=my_compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "4df6ab08",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set don't have a corresponding argument in `CamembertForSequenceClassification.forward` and have been ignored: translated_premise, text, premise, hypothesis, translated_hypothesis. If translated_premise, text, premise, hypothesis, translated_hypothesis are not expected by `CamembertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "/soe/sgarg6/conda/envs/nlp_env/lib/python3.10/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 549367\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 256\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 256\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 2146\n",
      "  Number of trainable parameters = 68097027\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2146' max='2146' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2146/2146 09:45, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>256</td>\n",
       "      <td>0.571900</td>\n",
       "      <td>0.673840</td>\n",
       "      <td>0.717334</td>\n",
       "      <td>0.716320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>512</td>\n",
       "      <td>0.678100</td>\n",
       "      <td>0.637535</td>\n",
       "      <td>0.731559</td>\n",
       "      <td>0.731528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>768</td>\n",
       "      <td>0.651300</td>\n",
       "      <td>0.616976</td>\n",
       "      <td>0.745682</td>\n",
       "      <td>0.745820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1024</td>\n",
       "      <td>0.642000</td>\n",
       "      <td>0.610716</td>\n",
       "      <td>0.747815</td>\n",
       "      <td>0.748559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1280</td>\n",
       "      <td>0.631300</td>\n",
       "      <td>0.587332</td>\n",
       "      <td>0.758281</td>\n",
       "      <td>0.758691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1536</td>\n",
       "      <td>0.619600</td>\n",
       "      <td>0.577981</td>\n",
       "      <td>0.760516</td>\n",
       "      <td>0.760139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1792</td>\n",
       "      <td>0.621200</td>\n",
       "      <td>0.569904</td>\n",
       "      <td>0.764377</td>\n",
       "      <td>0.764184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2048</td>\n",
       "      <td>0.608800</td>\n",
       "      <td>0.569622</td>\n",
       "      <td>0.763666</td>\n",
       "      <td>0.763428</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForSequenceClassification.forward` and have been ignored: translated_premise, text, premise, hypothesis, translated_hypothesis. If translated_premise, text, premise, hypothesis, translated_hypothesis are not expected by `CamembertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 9842\n",
      "  Batch size = 256\n",
      "Saving model checkpoint to /data/users/sgarg6/hf_models/quest-4/checkpoint-256\n",
      "Configuration saved in /data/users/sgarg6/hf_models/quest-4/checkpoint-256/config.json\n",
      "Model weights saved in /data/users/sgarg6/hf_models/quest-4/checkpoint-256/pytorch_model.bin\n",
      "tokenizer config file saved in /data/users/sgarg6/hf_models/quest-4/checkpoint-256/tokenizer_config.json\n",
      "Special tokens file saved in /data/users/sgarg6/hf_models/quest-4/checkpoint-256/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForSequenceClassification.forward` and have been ignored: translated_premise, text, premise, hypothesis, translated_hypothesis. If translated_premise, text, premise, hypothesis, translated_hypothesis are not expected by `CamembertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 9842\n",
      "  Batch size = 256\n",
      "Saving model checkpoint to /data/users/sgarg6/hf_models/quest-4/checkpoint-512\n",
      "Configuration saved in /data/users/sgarg6/hf_models/quest-4/checkpoint-512/config.json\n",
      "Model weights saved in /data/users/sgarg6/hf_models/quest-4/checkpoint-512/pytorch_model.bin\n",
      "tokenizer config file saved in /data/users/sgarg6/hf_models/quest-4/checkpoint-512/tokenizer_config.json\n",
      "Special tokens file saved in /data/users/sgarg6/hf_models/quest-4/checkpoint-512/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForSequenceClassification.forward` and have been ignored: translated_premise, text, premise, hypothesis, translated_hypothesis. If translated_premise, text, premise, hypothesis, translated_hypothesis are not expected by `CamembertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 9842\n",
      "  Batch size = 256\n",
      "Saving model checkpoint to /data/users/sgarg6/hf_models/quest-4/checkpoint-768\n",
      "Configuration saved in /data/users/sgarg6/hf_models/quest-4/checkpoint-768/config.json\n",
      "Model weights saved in /data/users/sgarg6/hf_models/quest-4/checkpoint-768/pytorch_model.bin\n",
      "tokenizer config file saved in /data/users/sgarg6/hf_models/quest-4/checkpoint-768/tokenizer_config.json\n",
      "Special tokens file saved in /data/users/sgarg6/hf_models/quest-4/checkpoint-768/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForSequenceClassification.forward` and have been ignored: translated_premise, text, premise, hypothesis, translated_hypothesis. If translated_premise, text, premise, hypothesis, translated_hypothesis are not expected by `CamembertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 9842\n",
      "  Batch size = 256\n",
      "Saving model checkpoint to /data/users/sgarg6/hf_models/quest-4/checkpoint-1024\n",
      "Configuration saved in /data/users/sgarg6/hf_models/quest-4/checkpoint-1024/config.json\n",
      "Model weights saved in /data/users/sgarg6/hf_models/quest-4/checkpoint-1024/pytorch_model.bin\n",
      "tokenizer config file saved in /data/users/sgarg6/hf_models/quest-4/checkpoint-1024/tokenizer_config.json\n",
      "Special tokens file saved in /data/users/sgarg6/hf_models/quest-4/checkpoint-1024/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForSequenceClassification.forward` and have been ignored: translated_premise, text, premise, hypothesis, translated_hypothesis. If translated_premise, text, premise, hypothesis, translated_hypothesis are not expected by `CamembertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 9842\n",
      "  Batch size = 256\n",
      "Saving model checkpoint to /data/users/sgarg6/hf_models/quest-4/checkpoint-1280\n",
      "Configuration saved in /data/users/sgarg6/hf_models/quest-4/checkpoint-1280/config.json\n",
      "Model weights saved in /data/users/sgarg6/hf_models/quest-4/checkpoint-1280/pytorch_model.bin\n",
      "tokenizer config file saved in /data/users/sgarg6/hf_models/quest-4/checkpoint-1280/tokenizer_config.json\n",
      "Special tokens file saved in /data/users/sgarg6/hf_models/quest-4/checkpoint-1280/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForSequenceClassification.forward` and have been ignored: translated_premise, text, premise, hypothesis, translated_hypothesis. If translated_premise, text, premise, hypothesis, translated_hypothesis are not expected by `CamembertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 9842\n",
      "  Batch size = 256\n",
      "Saving model checkpoint to /data/users/sgarg6/hf_models/quest-4/checkpoint-1536\n",
      "Configuration saved in /data/users/sgarg6/hf_models/quest-4/checkpoint-1536/config.json\n",
      "Model weights saved in /data/users/sgarg6/hf_models/quest-4/checkpoint-1536/pytorch_model.bin\n",
      "tokenizer config file saved in /data/users/sgarg6/hf_models/quest-4/checkpoint-1536/tokenizer_config.json\n",
      "Special tokens file saved in /data/users/sgarg6/hf_models/quest-4/checkpoint-1536/special_tokens_map.json\n",
      "Deleting older checkpoint [/data/users/sgarg6/hf_models/quest-4/checkpoint-256] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForSequenceClassification.forward` and have been ignored: translated_premise, text, premise, hypothesis, translated_hypothesis. If translated_premise, text, premise, hypothesis, translated_hypothesis are not expected by `CamembertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 9842\n",
      "  Batch size = 256\n",
      "Saving model checkpoint to /data/users/sgarg6/hf_models/quest-4/checkpoint-1792\n",
      "Configuration saved in /data/users/sgarg6/hf_models/quest-4/checkpoint-1792/config.json\n",
      "Model weights saved in /data/users/sgarg6/hf_models/quest-4/checkpoint-1792/pytorch_model.bin\n",
      "tokenizer config file saved in /data/users/sgarg6/hf_models/quest-4/checkpoint-1792/tokenizer_config.json\n",
      "Special tokens file saved in /data/users/sgarg6/hf_models/quest-4/checkpoint-1792/special_tokens_map.json\n",
      "Deleting older checkpoint [/data/users/sgarg6/hf_models/quest-4/checkpoint-512] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForSequenceClassification.forward` and have been ignored: translated_premise, text, premise, hypothesis, translated_hypothesis. If translated_premise, text, premise, hypothesis, translated_hypothesis are not expected by `CamembertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 9842\n",
      "  Batch size = 256\n",
      "Saving model checkpoint to /data/users/sgarg6/hf_models/quest-4/checkpoint-2048\n",
      "Configuration saved in /data/users/sgarg6/hf_models/quest-4/checkpoint-2048/config.json\n",
      "Model weights saved in /data/users/sgarg6/hf_models/quest-4/checkpoint-2048/pytorch_model.bin\n",
      "tokenizer config file saved in /data/users/sgarg6/hf_models/quest-4/checkpoint-2048/tokenizer_config.json\n",
      "Special tokens file saved in /data/users/sgarg6/hf_models/quest-4/checkpoint-2048/special_tokens_map.json\n",
      "Deleting older checkpoint [/data/users/sgarg6/hf_models/quest-4/checkpoint-768] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from /data/users/sgarg6/hf_models/quest-4/checkpoint-1792 (score: 0.7643771591140012).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=2146, training_loss=0.6380337664487755, metrics={'train_runtime': 585.4445, 'train_samples_per_second': 938.376, 'train_steps_per_second': 3.666, 'total_flos': 6145437024914634.0, 'train_loss': 0.6380337664487755, 'epoch': 1.0})"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 111;\n",
       "                var nbb_unformatted_code = \"trainer.train()\";\n",
       "                var nbb_formatted_code = \"trainer.train()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "4aa4ffed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 112;\n",
       "                var nbb_unformatted_code = \"model = trainer.model\";\n",
       "                var nbb_formatted_code = \"model = trainer.model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = trainer.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "e10080fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForSequenceClassification.forward` and have been ignored: translated_premise, text, premise, hypothesis, translated_hypothesis. If translated_premise, text, premise, hypothesis, translated_hypothesis are not expected by `CamembertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 9824\n",
      "  Batch size = 256\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='39' max='39' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [39/39 00:03]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'test_loss': 0.5801504850387573,\n",
       " 'test_accuracy': 0.7595684039087948,\n",
       " 'test_f1': 0.7595466066589128,\n",
       " 'test_runtime': 4.3199,\n",
       " 'test_samples_per_second': 2274.126,\n",
       " 'test_steps_per_second': 9.028,\n",
       " 'epoch': 1.0}"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 113;\n",
       "                var nbb_unformatted_code = \"trainer.evaluate(metric_key_prefix=\\\"test\\\", eval_dataset=dataset[\\\"test\\\"])\";\n",
       "                var nbb_formatted_code = \"trainer.evaluate(metric_key_prefix=\\\"test\\\", eval_dataset=dataset[\\\"test\\\"])\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.evaluate(metric_key_prefix=\"test\", eval_dataset=dataset[\"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b1d252a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    inputs = tokenizer(\n",
    "        \"<s> This is not entailment <sep> but this is\", return_tensors=\"pt\"\n",
    "    ).to(device)\n",
    "    logits = model(**inputs).logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d7eabc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc83d5a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
